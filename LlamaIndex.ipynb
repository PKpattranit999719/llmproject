{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ลองเปลี่ยนมาใช้ Llamalndex ในการกรองข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='http://111.223.37.52/v1'\n",
    "api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjp7Im9yZ2FuaXphdGlvbl9pZCI6IjY3MzU2NTczYWM4ZjUzNGEwMGUxNjkzZiIsInRva2VuX25hbWUiOiJTRFAtREVWIiwic3RkRGF0ZSI6IjIwMjQtMTEtMTdUMTc6MDA6MDAuMDAwWiJ9LCJpYXQiOjE3MzE5MTczNzksImV4cCI6MTc4Mjc1MjM5OX0.XLU98w0PT4Gy_PzlLhHVWMawkEH8pWpxsYzt3Ffw6xE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Data Loading\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# สร้างโมเดลที่ใช้เชื่อมต่อกับเซิร์ฟเวอร์กลาง\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    base_url=url,  # URL ของเซิร์ฟเวอร์กลาง\n",
    "    api_key=api_key,  # API Key สำหรับการเข้าถึงเซิร์ฟเวอร์\n",
    "    max_tokens=1000  # จำกัดจำนวนโทเค็นในคำตอบ\n",
    ")\n",
    "\n",
    "# โหลดข้อมูล\n",
    "df = pd.read_csv(\"splitData.csv\")  # โหลดไฟล์ข้อมูล\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Distance Calculation : คำนวณระยะทางระหว่างตำแหน่งผู้ใช้กับสถานที่ใน DataFrame\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def calculate_distance(user_location, place_location):\n",
    "    return geodesic(user_location, place_location).kilometers\n",
    "\n",
    "# ลบแถวที่มีค่า NaN ในคอลัมน์ LATITUDE_LOCATION และ LONGITUDE_LOCATION\n",
    "df = df.dropna(subset=['LATITUDE_LOCATION', 'LONGITUDE_LOCATION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Keyword Extraction : ใช้ LLM เพื่อแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "def extract_keywords_from_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ใช้โมเดล LLM เพื่อแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "    \"\"\"\n",
    "    # ส่งคำถามไปยังโมเดล LLM\n",
    "    response = llm.invoke(f\"แยกคำสำคัญจากคำถามนี้: '{query}' และแสดงคำสำคัญที่เกี่ยวข้องที่สามารถใช้กรองข้อมูลได้\")\n",
    "    \n",
    "    # ตรวจสอบผลลัพธ์และคืนค่าคำสำคัญ\n",
    "    return response.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำสำคัญที่ได้จากคำถาม: คำสำคัญจากคำถาม \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\" ได้แก่:\n",
      "\n",
      "1. แหล่งท่องเที่ยว\n",
      "2. ทางธรรมชาติ\n",
      "3. จังหวัด\n",
      "4. นครปฐม\n",
      "\n",
      "คำสำคัญที่เกี่ยวข้องที่สามารถใช้กรองข้อมูลได้:\n",
      "\n",
      "- แหล่งท่องเที่ยว\n",
      "- ธรรมชาติ\n",
      "- จังหวัดนครปฐม\n",
      "- สถานที่ท่องเที่ยว\n",
      "- กิจกรรมกลางแจ้ง\n",
      "- สถานที่พักผ่อน\n",
      "- ความสวยงามของธรรมชาติ\n"
     ]
    }
   ],
   "source": [
    "# 4 Example Query and Extraction\n",
    "# ตัวอย่างคำถามจากผู้ใช้\n",
    "user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "\n",
    "# แยกคำสำคัญจากคำถาม\n",
    "keywords = extract_keywords_from_query(user_query)\n",
    "print(\"คำสำคัญที่ได้จากคำถาม:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ข้อมูลที่กรองแล้ว:\n",
      "                      ATT_NAME_TH PROVINCE_NAME_TH  LATITUDE_LOCATION  \\\n",
      "0                   เสาหินบะซอลต์        บุรีรัมย์          14.583138   \n",
      "1                อ่างเก็บน้ำลำพอก         สุรินทร์          14.931604   \n",
      "2                อ่างเก็บน้ำลำพอก         สุรินทร์          14.931604   \n",
      "3     กลุ่มสตรีทอผ้าบ้านท่ากระจาย     สุราษฎร์ธานี           9.590320   \n",
      "4                  องค์ศรีสุขคเณศ         อุดรธานี          17.411384   \n",
      "...                           ...              ...                ...   \n",
      "8237                   วัดจอมธรรม        เชียงใหม่          18.632262   \n",
      "8238                 น้ำตกวชิรธาร        เชียงใหม่          18.542003   \n",
      "8239           น้ำพุร้อนโป่งเดือด        เชียงใหม่          19.243291   \n",
      "8240                     ผาจูบกัน        เชียงใหม่          18.222642   \n",
      "8241                       อ่างกา        เชียงใหม่          18.588454   \n",
      "\n",
      "      LONGITUDE_LOCATION  \n",
      "0             102.805353  \n",
      "1             103.836118  \n",
      "2             103.836118  \n",
      "3              99.200535  \n",
      "4             102.780703  \n",
      "...                  ...  \n",
      "8237           99.282558  \n",
      "8238           98.598254  \n",
      "8239           98.683469  \n",
      "8240           98.481617  \n",
      "8241           98.486105  \n",
      "\n",
      "[8241 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5 Data Filtering : กรองข้อมูลตามคำสำคัญจากคำถามของผู้ใช้\n",
    "# แยกคำสำคัญที่เกี่ยวข้องกับการกรองข้อมูลออกจาก keywords ที่ได้\n",
    "province = None\n",
    "category = None\n",
    "\n",
    "# กรองข้อมูลตามคำสำคัญที่ได้\n",
    "filtered_data = df\n",
    "if 'province' in keywords:\n",
    "    province = keywords['province']\n",
    "    filtered_data = filtered_data[filtered_data['PROVINCE_NAME_TH'].str.contains(province, na=False, case=False)]\n",
    "\n",
    "if 'category' in keywords:\n",
    "    category = keywords['category']\n",
    "    filtered_data = filtered_data[filtered_data['ATTR_CATAGORY_TH'].str.contains(category, na=False, case=False)]\n",
    "\n",
    "print(\"ข้อมูลที่กรองแล้ว:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ข้อมูลที่กรองแล้วในรัศมี 50 กิโลเมตร:\n",
      "                       ATT_NAME_TH PROVINCE_NAME_TH  LATITUDE_LOCATION  \\\n",
      "48              ชุมชนเกาะลัดอีแท่น           นครปฐม          13.756728   \n",
      "130    พิพิธภัณฑสถานแห่งชาติอู่ทอง       สุพรรณบุรี          14.372874   \n",
      "165         วัดราษฎร์ศรัทธากะยาราม        สมุทรสาคร          13.590556   \n",
      "191   กลุ่มสตรีพัฒนากล้วยน้ำว้าไทย        กาญจนบุรี          14.071364   \n",
      "203               วูดแลนด์เมืองไม้           นครปฐม          13.858140   \n",
      "...                            ...              ...                ...   \n",
      "8175              สมาภรณ์ การ์เด้น        สมุทรสาคร          13.603811   \n",
      "8189                สวนส้มโอไทยทวี           นครปฐม          13.823086   \n",
      "8196                 วัดญาณเวศกวัน           นครปฐม          13.770129   \n",
      "8197                  วัดดอนยายหอม           นครปฐม          13.736541   \n",
      "8221                  บ้านสวนปรีดา           นครปฐม          13.785711   \n",
      "\n",
      "      LONGITUDE_LOCATION   DISTANCE  \n",
      "48            100.273436  43.403274  \n",
      "130            99.891780  39.844790  \n",
      "165           100.107778  49.827034  \n",
      "191            99.658774  34.932552  \n",
      "203           100.217217  31.594197  \n",
      "...                  ...        ...  \n",
      "8175          100.051348  47.021979  \n",
      "8189          100.196408  32.304472  \n",
      "8196          100.308746  45.350937  \n",
      "8197          100.080984  33.557106  \n",
      "8221          100.282918  42.090851  \n",
      "\n",
      "[330 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6 Distance Filtering : กรองข้อมูลตามระยะทางจากพิกัดของผู้ใช้\n",
    "user_location = (14.022788, 99.978337)  # พิกัดของผู้ใช้\n",
    "radius = 50  # รัศมี 50 กิโลเมตร\n",
    "\n",
    "# คำนวณระยะทางและกรองข้อมูลตามระยะทาง\n",
    "filtered_data['DISTANCE'] = filtered_data.apply(\n",
    "    lambda row: calculate_distance(user_location, (row['LATITUDE_LOCATION'], row['LONGITUDE_LOCATION'])), axis=1\n",
    ")\n",
    "filtered_data = filtered_data[filtered_data['DISTANCE'] <= radius]\n",
    "\n",
    "print(\"ข้อมูลที่กรองแล้วในรัศมี 50 กิโลเมตร:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION', 'DISTANCE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สถานที่ท่องเที่ยวที่กรองแล้วในรัศมี 50 กิโลเมตร:\n",
      "                       ATT_NAME_TH PROVINCE_NAME_TH  LATITUDE_LOCATION  \\\n",
      "48              ชุมชนเกาะลัดอีแท่น           นครปฐม          13.756728   \n",
      "130    พิพิธภัณฑสถานแห่งชาติอู่ทอง       สุพรรณบุรี          14.372874   \n",
      "165         วัดราษฎร์ศรัทธากะยาราม        สมุทรสาคร          13.590556   \n",
      "191   กลุ่มสตรีพัฒนากล้วยน้ำว้าไทย        กาญจนบุรี          14.071364   \n",
      "203               วูดแลนด์เมืองไม้           นครปฐม          13.858140   \n",
      "...                            ...              ...                ...   \n",
      "8175              สมาภรณ์ การ์เด้น        สมุทรสาคร          13.603811   \n",
      "8189                สวนส้มโอไทยทวี           นครปฐม          13.823086   \n",
      "8196                 วัดญาณเวศกวัน           นครปฐม          13.770129   \n",
      "8197                  วัดดอนยายหอม           นครปฐม          13.736541   \n",
      "8221                  บ้านสวนปรีดา           นครปฐม          13.785711   \n",
      "\n",
      "      LONGITUDE_LOCATION   DISTANCE  \n",
      "48            100.273436  43.403274  \n",
      "130            99.891780  39.844790  \n",
      "165           100.107778  49.827034  \n",
      "191            99.658774  34.932552  \n",
      "203           100.217217  31.594197  \n",
      "...                  ...        ...  \n",
      "8175          100.051348  47.021979  \n",
      "8189          100.196408  32.304472  \n",
      "8196          100.308746  45.350937  \n",
      "8197          100.080984  33.557106  \n",
      "8221          100.282918  42.090851  \n",
      "\n",
      "[330 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 7 Final Output : แสดงผลลัพธ์สุดท้าย\n",
    "print(\"สถานที่ท่องเที่ยวที่กรองแล้วในรัศมี 50 กิโลเมตร:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION', 'DISTANCE']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ลองใหม่อีกที"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in .\\testenv\\lib\\site-packages (0.12.5)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.5 in .\\testenv\\lib\\site-packages (from llama_index) (0.12.5)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in .\\testenv\\lib\\site-packages (from llama_index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.10)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in .\\testenv\\lib\\site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in .\\testenv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.57.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in .\\testenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama_index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (2024.10.0)\n",
      "Requirement already satisfied: httpx in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (3.4.2)\n",
      "Requirement already satisfied: numpy in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.5->llama_index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in .\\testenv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.6)\n",
      "Requirement already satisfied: pandas in .\\testenv\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.5.17)\n",
      "Requirement already satisfied: click in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\testenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
      "Requirement already satisfied: anyio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (4.7.0)\n",
      "Requirement already satisfied: certifi in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.0.7)\n",
      "Requirement already satisfied: idna in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (3.10)\n",
      "Requirement already satisfied: sniffio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\testenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.5->llama_index) (0.14.0)\n",
      "Requirement already satisfied: colorama in .\\testenv\\lib\\site-packages (from click->nltk>3.8.1->llama_index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.8.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama_index) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama_index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama_index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\testenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama_index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\testenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.5->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\testenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama_index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\testenv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\testenv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\testenv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in .\\testenv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama_index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\testenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install llama_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in .\\testenv\\lib\\site-packages (0.12.5)\n",
      "Collecting llama_index\n",
      "  Downloading llama_index-0.12.9-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.9 (from llama_index)\n",
      "  Downloading llama_index_core-0.12.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.10)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in .\\testenv\\lib\\site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in .\\testenv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.57.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in .\\testenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2024.10.0)\n",
      "Requirement already satisfied: httpx in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (3.4.2)\n",
      "Requirement already satisfied: numpy in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in .\\testenv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.6)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.12.3)\n",
      "Requirement already satisfied: pandas in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.5.17)\n",
      "Requirement already satisfied: click in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\testenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
      "Requirement already satisfied: anyio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (4.7.0)\n",
      "Requirement already satisfied: certifi in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.7)\n",
      "Requirement already satisfied: idna in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.10)\n",
      "Requirement already satisfied: sniffio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\testenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.14.0)\n",
      "Requirement already satisfied: colorama in .\\testenv\\lib\\site-packages (from click->nltk>3.8.1->llama_index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.8.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\testenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\testenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\testenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in .\\testenv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.9->llama_index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\testenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n",
      "Downloading llama_index-0.12.9-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.12.9-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: llama-index-core, llama_index\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.5\n",
      "    Uninstalling llama-index-core-0.12.5:\n",
      "      Successfully uninstalled llama-index-core-0.12.5\n",
      "  Attempting uninstall: llama_index\n",
      "    Found existing installation: llama-index 0.12.5\n",
      "    Uninstalling llama-index-0.12.5:\n",
      "      Successfully uninstalled llama-index-0.12.5\n",
      "Successfully installed llama-index-core-0.12.9 llama_index-0.12.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install llama_index --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ServiceContext' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServiceContext, SimpleKeywordTableIndex\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# โหลดข้อมูลจากไฟล์ CSV\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ServiceContext' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, SimpleKeywordTableIndex\n",
    "import pandas as pd\n",
    "\n",
    "# โหลดข้อมูลจากไฟล์ CSV\n",
    "df = pd.read_csv(\"splitData.csv\")\n",
    "\n",
    "# ตรวจสอบว่ามีข้อมูลครบถ้วนหรือไม่\n",
    "print(df.columns)  # ดูคอลัมน์ทั้งหมด\n",
    "\n",
    "# แปลงข้อมูลจาก DataFrame เป็นเอกสาร (Document)\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    document = {\n",
    "        'text': row['ATT_NAME_TH'],  # ชื่อสถานที่\n",
    "        'metadata': {\n",
    "            'LATITUDE': row['LATITUDE_LOCATION'],\n",
    "            'LONGITUDE': row['LONGITUDE_LOCATION'],\n",
    "            'PROVINCE': row['PROVINCE_NAME_TH'],\n",
    "            'CATEGORY': row['ATTR_CATAGORY_TH'],\n",
    "        }\n",
    "    }\n",
    "    documents.append(document)\n",
    "\n",
    "# สร้าง ServiceContext สำหรับใช้งาน\n",
    "service_context = ServiceContext.from_defaults()\n",
    "\n",
    "# สร้าง SimpleKeywordTableIndex จากเอกสาร\n",
    "index = SimpleKeywordTableIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "# ตรวจสอบการสร้างดัชนี\n",
    "print(\"Index created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-indexNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.12.9\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: c:\\llmproject\\testenv\\Lib\\site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show llama_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\llmproject\\testenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[12], line 40\u001b[0m\n    keywords = extract_keywords_from_query(user_query)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 34\u001b[1;36m in \u001b[1;35mextract_keywords_from_query\u001b[1;36m\n\u001b[1;33m    return eval(response.content.strip())\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    คำสำคัญจากคำถาม 'ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย' ได้แก่:\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.core import VectorStoreIndex,ServiceContext,Document\n",
    "import ast\n",
    "\n",
    "# 1. สร้างโมเดลที่ใช้เชื่อมต่อกับเซิร์ฟเวอร์กลาง\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    base_url=url,  # URL ของเซิร์ฟเวอร์กลาง\n",
    "    api_key=api_key,  # API Key สำหรับการเข้าถึงเซิร์ฟเวอร์\n",
    "    max_tokens=1000  # จำกัดจำนวนโทเค็นในคำตอบ\n",
    ")\n",
    "\n",
    "# 2. โหลดข้อมูลจากไฟล์ CSV\n",
    "df = pd.read_csv(\"splitData.csv\")  # โหลดไฟล์ข้อมูล\n",
    "\n",
    "# 3. ฟังก์ชันคำนวณระยะทาง\n",
    "def calculate_distance(user_location, place_location):\n",
    "    return geodesic(user_location, place_location).kilometers\n",
    "\n",
    "# ลบแถวที่มีค่า NaN ในคอลัมน์ LATITUDE_LOCATION และ LONGITUDE_LOCATION\n",
    "df = df.dropna(subset=['LATITUDE_LOCATION', 'LONGITUDE_LOCATION'])\n",
    "\n",
    "# 4. ฟังก์ชันแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "def extract_keywords_from_query(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    ใช้โมเดล LLM เพื่อแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "    \"\"\"\n",
    "    # ส่งคำถามไปยังโมเดล LLM\n",
    "    response = llm.invoke(f\"แยกคำสำคัญจากคำถามนี้: '{query}' และแสดงคำสำคัญที่เกี่ยวข้องที่สามารถใช้กรองข้อมูลได้\")\n",
    "    \n",
    "    # ใช้ eval เพื่อแปลงคำตอบเป็น dictionary (ควรระมัดระวังในการใช้ eval)\n",
    "    return eval(response.content.strip())\n",
    "\n",
    "# 5. ตัวอย่างคำถามจากผู้ใช้\n",
    "user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "\n",
    "# แยกคำสำคัญจากคำถาม\n",
    "keywords = extract_keywords_from_query(user_query)\n",
    "print(\"คำสำคัญที่ได้จากคำถาม:\", keywords)\n",
    "\n",
    "# 6. สร้าง Documents จาก DataFrame เพื่อใช้งานกับ LlamaIndex\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    document = Document(\n",
    "        text=row['ATT_NAME_TH'],  # ชื่อสถานที่\n",
    "        metadata={  # ข้อมูลที่เกี่ยวข้อง\n",
    "            'LATITUDE': row['LATITUDE_LOCATION'],\n",
    "            'LONGITUDE': row['LONGITUDE_LOCATION'],\n",
    "            'PROVINCE': row['PROVINCE_NAME_TH'],\n",
    "            'CATEGORY': row['ATTR_CATAGORY_TH'],\n",
    "        }\n",
    "    )\n",
    "    documents.append(document)\n",
    "\n",
    "# 7. สร้าง Index จาก Documents ด้วย VectorStoreIndex\n",
    "service_context = ServiceContext.from_defaults()\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "# 8. การค้นหาข้อมูลจากคำสำคัญ (กรองตามคำสำคัญจากคำถาม)\n",
    "keyword_search = \"province:\" + keywords.get(\"province\", \"\") + \" category:\" + keywords.get(\"category\", \"\")\n",
    "query_response = index.query(keyword_search)\n",
    "\n",
    "# 9. กรองข้อมูลตามระยะทางจากพิกัดของผู้ใช้\n",
    "user_location = (14.022788, 99.978337)  # พิกัดของผู้ใช้\n",
    "radius = 50  # รัศมี 50 กิโลเมตร\n",
    "\n",
    "# คำนวณระยะทางและกรองข้อมูลตามระยะทาง\n",
    "filtered_data = pd.DataFrame(query_response)  # เปลี่ยนข้อมูลที่ได้จากการค้นหาเป็น DataFrame\n",
    "filtered_data['DISTANCE'] = filtered_data.apply(\n",
    "    lambda row: calculate_distance(user_location, (row['LATITUDE'], row['LONGITUDE'])), axis=1\n",
    ")\n",
    "\n",
    "# กรองข้อมูลที่มีระยะทางภายในรัศมีที่กำหนด\n",
    "filtered_data = filtered_data[filtered_data['DISTANCE'] <= radius]\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"ข้อมูลที่กรองแล้วในรัศมี 50 กิโลเมตร:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION', 'DISTANCE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in .\\testenv\\lib\\site-packages (0.12.9)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.9 in .\\testenv\\lib\\site-packages (from llama_index) (0.12.9)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.10)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in .\\testenv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in .\\testenv\\lib\\site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in .\\testenv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.57.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in .\\testenv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2024.10.0)\n",
      "Requirement already satisfied: httpx in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (3.4.2)\n",
      "Requirement already satisfied: numpy in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in .\\testenv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.9->llama_index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in .\\testenv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.6)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.12.3)\n",
      "Requirement already satisfied: pandas in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in .\\testenv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in .\\testenv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.5.17)\n",
      "Requirement already satisfied: click in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in .\\testenv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\testenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\testenv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
      "Requirement already satisfied: anyio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (4.7.0)\n",
      "Requirement already satisfied: certifi in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.7)\n",
      "Requirement already satisfied: idna in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.10)\n",
      "Requirement already satisfied: sniffio in .\\testenv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\testenv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.14.0)\n",
      "Requirement already satisfied: colorama in .\\testenv\\lib\\site-packages (from click->nltk>3.8.1->llama_index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\testenv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.8.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in .\\testenv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\testenv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\testenv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\testenv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.9->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\testenv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.9->llama_index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\testenv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in .\\testenv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.9->llama_index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\testenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เกิดข้อผิดพลาดในการแปลงข้อมูล: invalid syntax (<unknown>, line 1)\n",
      "คำสำคัญที่ได้จากคำถาม: {}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_Settings' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     documents\u001b[38;5;241m.\u001b[39mappend(document)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# 7. สร้าง Settings สำหรับการสร้าง Index\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ใส่ค่าการตั้งค่าที่ต้องการ\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ถ้าคุณใช้ embedding ใดๆ\u001b[39;49;00m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# เพิ่มค่าอื่นๆ ถ้าต้องการ\u001b[39;49;00m\n\u001b[0;32m     71\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# 8. สร้าง Index จาก Documents ด้วย VectorStoreIndex\u001b[39;00m\n\u001b[0;32m     74\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(documents, settings\u001b[38;5;241m=\u001b[39msettings)\n",
      "\u001b[1;31mTypeError\u001b[0m: '_Settings' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.core import VectorStoreIndex,Document\n",
    "import ast\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "# 1. สร้างโมเดลที่ใช้เชื่อมต่อกับเซิร์ฟเวอร์กลาง\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    base_url=url,  # URL ของเซิร์ฟเวอร์กลาง\n",
    "    api_key=api_key,  # API Key สำหรับการเข้าถึงเซิร์ฟเวอร์\n",
    "    max_tokens=1000  # จำกัดจำนวนโทเค็นในคำตอบ\n",
    ")\n",
    "\n",
    "# 2. โหลดข้อมูลจากไฟล์ CSV\n",
    "df = pd.read_csv(\"splitData.csv\")  # โหลดไฟล์ข้อมูล\n",
    "\n",
    "# 3. ฟังก์ชันคำนวณระยะทาง\n",
    "def calculate_distance(user_location, place_location):\n",
    "    return geodesic(user_location, place_location).kilometers\n",
    "\n",
    "# ลบแถวที่มีค่า NaN ในคอลัมน์ LATITUDE_LOCATION และ LONGITUDE_LOCATION\n",
    "df = df.dropna(subset=['LATITUDE_LOCATION', 'LONGITUDE_LOCATION'])\n",
    "\n",
    "# 4. ฟังก์ชันแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "def extract_keywords_from_query(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    ใช้โมเดล LLM เพื่อแยกคำสำคัญจากคำถามของผู้ใช้\n",
    "    \"\"\"\n",
    "    # ส่งคำถามไปยังโมเดล LLM\n",
    "    response = llm.invoke(f\"แยกคำสำคัญจากคำถามนี้: '{query}' และแสดงคำสำคัญที่เกี่ยวข้องที่สามารถใช้กรองข้อมูลได้\")\n",
    "    \n",
    "    # ใช้ ast.literal_eval() เพื่อแปลงข้อความที่ได้เป็น dict อย่างปลอดภัย\n",
    "    try:\n",
    "        # แปลงข้อความที่ได้จากโมเดลให้เป็น dictionary\n",
    "        return ast.literal_eval(response.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการแปลงข้อมูล: {e}\")\n",
    "        return {}\n",
    "\n",
    "# 5. ตัวอย่างคำถามจากผู้ใช้\n",
    "user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "\n",
    "# แยกคำสำคัญจากคำถาม\n",
    "keywords = extract_keywords_from_query(user_query)\n",
    "print(\"คำสำคัญที่ได้จากคำถาม:\", keywords)\n",
    "\n",
    "# 6. สร้าง Documents จาก DataFrame เพื่อใช้งานกับ LlamaIndex\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    document = Document(\n",
    "        text=row['ATT_NAME_TH'],  # ชื่อสถานที่\n",
    "        metadata={  # ข้อมูลที่เกี่ยวข้อง\n",
    "            'LATITUDE': row['LATITUDE_LOCATION'],\n",
    "            'LONGITUDE': row['LONGITUDE_LOCATION'],\n",
    "            'PROVINCE': row['PROVINCE_NAME_TH'],\n",
    "            'CATEGORY': row['ATTR_CATAGORY_TH'],\n",
    "        }\n",
    "    )\n",
    "    documents.append(document)\n",
    "\n",
    "# 7. สร้าง Settings สำหรับการสร้าง Index\n",
    "settings = Settings(\n",
    "    # ใส่ค่าการตั้งค่าที่ต้องการ\n",
    "    embedding_mode='default',  # ถ้าคุณใช้ embedding ใดๆ\n",
    "    # เพิ่มค่าอื่นๆ ถ้าต้องการ\n",
    ")\n",
    "\n",
    "# 8. สร้าง Index จาก Documents ด้วย VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents, settings=settings)\n",
    "\n",
    "# 9. การค้นหาข้อมูลจากคำสำคัญ (กรองตามคำสำคัญจากคำถาม)\n",
    "keyword_search = \"province:\" + keywords.get(\"province\", \"\") + \" category:\" + keywords.get(\"category\", \"\")\n",
    "query_response = index.query(keyword_search)\n",
    "\n",
    "# 10. กรองข้อมูลตามระยะทางจากพิกัดของผู้ใช้\n",
    "user_location = (14.022788, 99.978337)  # พิกัดของผู้ใช้\n",
    "radius = 50  # รัศมี 50 กิโลเมตร\n",
    "\n",
    "# คำนวณระยะทางและกรองข้อมูลตามระยะทาง\n",
    "filtered_data = pd.DataFrame(query_response)  # เปลี่ยนข้อมูลที่ได้จากการค้นหาเป็น DataFrame\n",
    "filtered_data['DISTANCE'] = filtered_data.apply(\n",
    "    lambda row: calculate_distance(user_location, (row['LATITUDE'], row['LONGITUDE'])), axis=1\n",
    ")\n",
    "\n",
    "# กรองข้อมูลที่มีระยะทางภายในรัศมีที่กำหนด\n",
    "filtered_data = filtered_data[filtered_data['DISTANCE'] <= radius]\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"ข้อมูลที่กรองแล้วในรัศมี 50 กิโลเมตร:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION', 'DISTANCE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m Settings\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m OpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# สร้าง Index\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# ตัวอย่างคำถาม\u001b[39;00m\n\u001b[0;32m    104\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:119\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[0;32m    112\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[0;32m    113\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     transformations,\n\u001b[0;32m    115\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    117\u001b[0m )\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:76\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:77\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 77\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:310\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:232\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[1;32m--> 232\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39madd(nodes_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:139\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_node_with_embedding\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m    130\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     id_to_embed_map \u001b[38;5;241m=\u001b[39m \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\indices\\utils.py:160\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         id_to_embed_map[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m--> 160\u001b[0m new_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    165\u001b[0m     id_to_embed_map[new_id] \u001b[38;5;241m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:335\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    327\u001b[0m     EmbeddingStartEvent(\n\u001b[0;32m    328\u001b[0m         model_dict\u001b[38;5;241m=\u001b[39mmodel_dict,\n\u001b[0;32m    329\u001b[0m     )\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    332\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mEMBEDDING,\n\u001b[0;32m    333\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mSERIALIZED: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict()},\n\u001b[0;32m    334\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 335\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     result_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    337\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    338\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    339\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    340\u001b[0m             EventPayload\u001b[38;5;241m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    341\u001b[0m         },\n\u001b[0;32m    342\u001b[0m     )\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:465\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retryable_get_embeddings\u001b[39m():\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    459\u001b[0m         client,\n\u001b[0;32m    460\u001b[0m         texts,\n\u001b[0;32m    461\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_engine,\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs,\n\u001b[0;32m    463\u001b[0m     )\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retryable_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:458\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[1;34m()\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retryable_get_embeddings\u001b[39m():\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\llama_index\\embeddings\\openai\\base.py:169\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(client, list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch size should not be larger than 2048.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m list_of_text \u001b[38;5;241m=\u001b[39m [text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 169\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_of_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [d\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llmproject\\testenv\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "import ast\n",
    "\n",
    "# ฟังก์ชันตั้งค่า LLM Model\n",
    "def create_llm(base_url: str, api_key: str):\n",
    "    try:\n",
    "        return ChatOpenAI(\n",
    "            model='gpt-4o-mini',\n",
    "            base_url=base_url,  # URL ของเซิร์ฟเวอร์กลาง\n",
    "            api_key=api_key,  # API Key สำหรับการเข้าถึงเซิร์ฟเวอร์\n",
    "            max_tokens=1000  # จำกัดจำนวนโทเค็นในคำตอบ\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการสร้าง LLM: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ฟังก์ชันโหลดข้อมูล\n",
    "def load_data(file_path: str):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df.dropna(subset=['LATITUDE_LOCATION', 'LONGITUDE_LOCATION'])  # ลบแถวที่มีค่า NaN\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการโหลดข้อมูล: {e}\")\n",
    "        return None\n",
    "\n",
    "# ฟังก์ชันคำนวณระยะทาง\n",
    "def calculate_distance(user_location, place_location):\n",
    "    return geodesic(user_location, place_location).kilometers\n",
    "\n",
    "# ฟังก์ชันแยกคำสำคัญจากคำถาม\n",
    "def extract_keywords_from_query(llm, query: str) -> dict:\n",
    "    try:\n",
    "        response = llm.invoke(f\"แยกคำสำคัญจากคำถามนี้: '{query}' และแสดงคำสำคัญที่เกี่ยวข้องที่สามารถใช้กรองข้อมูลได้\")\n",
    "        return ast.literal_eval(response.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการแยกคำสำคัญ: {e}\")\n",
    "        return {}\n",
    "\n",
    "# ฟังก์ชันสร้าง Documents\n",
    "def create_documents(df):\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        documents.append(Document(\n",
    "            text=row['ATT_NAME_TH'],\n",
    "            metadata={\n",
    "                'LATITUDE': row['LATITUDE_LOCATION'],\n",
    "                'LONGITUDE': row['LONGITUDE_LOCATION'],\n",
    "                'PROVINCE': row['PROVINCE_NAME_TH'],\n",
    "                'CATEGORY': row['ATTR_CATAGORY_TH'],\n",
    "            }\n",
    "        ))\n",
    "    return documents\n",
    "\n",
    "# ฟังก์ชันกรองข้อมูลตามระยะทาง\n",
    "def filter_by_distance(query_response, user_location, radius):\n",
    "    result_data = []\n",
    "    for result in query_response:\n",
    "        lat, long = result.metadata['LATITUDE'], result.metadata['LONGITUDE']\n",
    "        distance = calculate_distance(user_location, (lat, long))\n",
    "        if distance <= radius:\n",
    "            result_data.append({\n",
    "                'ATT_NAME_TH': result.text,\n",
    "                'PROVINCE': result.metadata['PROVINCE'],\n",
    "                'LATITUDE': lat,\n",
    "                'LONGITUDE': long,\n",
    "                'DISTANCE': distance\n",
    "            })\n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "# เริ่มต้นโปรแกรม\n",
    "if __name__ == \"__main__\":\n",
    "    # ตั้งค่าข้อมูลเบื้องต้น\n",
    "    FILE_PATH = \"splitData.csv\"\n",
    "    USER_LOCATION = (14.022788, 99.978337)\n",
    "    RADIUS = 50  # รัศมี 50 กิโลเมตร\n",
    "    BASE_URL = \"http://111.223.37.52/v1\"  # ใส่ URL ของเซิร์ฟเวอร์\n",
    "    API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjp7Im9yZ2FuaXphdGlvbl9pZCI6IjY3MzU2NTczYWM4ZjUzNGEwMGUxNjkzZiIsInRva2VuX25hbWUiOiJTRFAtREVWIiwic3RkRGF0ZSI6IjIwMjQtMTEtMTdUMTc6MDA6MDAuMDAwWiJ9LCJpYXQiOjE3MzE5MTczNzksImV4cCI6MTc4Mjc1MjM5OX0.XLU98w0PT4Gy_PzlLhHVWMawkEH8pWpxsYzt3Ffw6xE\"  # ใส่ API Key ที่ใช้งาน\n",
    "\n",
    "    # สร้าง LLM Model\n",
    "    llm = create_llm(BASE_URL, API_KEY)\n",
    "    if not llm:\n",
    "        exit()\n",
    "\n",
    "    # โหลดข้อมูล\n",
    "    df = load_data(FILE_PATH)\n",
    "    if df is None:\n",
    "        exit()\n",
    "\n",
    "    # สร้างเอกสาร\n",
    "    documents = create_documents(df)\n",
    "\n",
    "    # สร้าง Settings\n",
    "    Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "    # สร้าง Index\n",
    "    index = VectorStoreIndex.from_documents(documents, settings=Settings)\n",
    "\n",
    "    # ตัวอย่างคำถาม\n",
    "    user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "    keywords = extract_keywords_from_query(llm, user_query)\n",
    "\n",
    "    # การค้นหาข้อมูลจากคำสำคัญ\n",
    "    keyword_search = f\"province:{keywords.get('province', '')} category:{keywords.get('category', '')}\"\n",
    "    query_response = index.query(keyword_search)\n",
    "\n",
    "    # กรองข้อมูลตามระยะทาง\n",
    "    filtered_data = filter_by_distance(query_response, USER_LOCATION, RADIUS)\n",
    "\n",
    "    # แสดงผลลัพธ์\n",
    "    if not filtered_data.empty:\n",
    "        print(\"ข้อมูลที่กรองแล้วในรัศมี 50 กิโลเมตร:\")\n",
    "        print(filtered_data[['ATT_NAME_TH', 'PROVINCE', 'LATITUDE', 'LONGITUDE', 'DISTANCE']])\n",
    "    else:\n",
    "        print(\"ไม่พบข้อมูลที่ตรงกับเงื่อนไข\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_keywords_from_query() missing 1 required positional argument: 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# แยกคำสำคัญจากคำถาม\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mextract_keywords_from_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mคำสำคัญที่ได้จากคำถาม:\u001b[39m\u001b[38;5;124m\"\u001b[39m, keywords)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# การกรองข้อมูลจากคำสำคัญที่ได้\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_keywords_from_query() missing 1 required positional argument: 'query'"
     ]
    }
   ],
   "source": [
    "# คำถามจากผู้ใช้\n",
    "user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "\n",
    "# แยกคำสำคัญจากคำถาม\n",
    "keywords = extract_keywords_from_query(user_query)\n",
    "print(\"คำสำคัญที่ได้จากคำถาม:\", keywords)\n",
    "\n",
    "# การกรองข้อมูลจากคำสำคัญที่ได้\n",
    "province = None\n",
    "category = None\n",
    "\n",
    "# สมมติว่า keywords เป็น dictionary ที่มี 'province' และ 'category'\n",
    "if 'province' in keywords:\n",
    "    province = keywords['province']\n",
    "    print(f\"กรองข้อมูลตามจังหวัด: {province}\")\n",
    "    filtered_data = df[df['PROVINCE_NAME_TH'].str.contains(province, na=False, case=False)]\n",
    "\n",
    "if 'category' in keywords:\n",
    "    category = keywords['category']\n",
    "    print(f\"กรองข้อมูลตามประเภท: {category}\")\n",
    "    filtered_data = filtered_data[filtered_data['ATTR_CATAGORY_TH'].str.contains(category, na=False, case=False)]\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"ข้อมูลที่กรองแล้ว:\")\n",
    "print(filtered_data[['ATT_NAME_TH', 'PROVINCE_NAME_TH', 'LATITUDE_LOCATION', 'LONGITUDE_LOCATION']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (3076992215.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[36], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "# คำถามจากผู้ใช้\n",
    "user_query = \"ช่วยหาแหล่งท่องเที่ยวทางธรรมชาติในจังหวัดนครปฐมให้หน่อย\"\n",
    "\n",
    "# แยกคำสำคัญจากคำถาม\n",
    "keywords = extract_keywords_from_query(user_query)\n",
    "print(\"คำสำคัญที่ได้จากคำถาม:\", keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
